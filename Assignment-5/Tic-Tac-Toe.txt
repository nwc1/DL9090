import numpy as np
import random

class TicTacToe:
    def __init__(self):
        self.board = np.zeros((3, 3), dtype=int)
        self.current_player = 1  # Player 1 starts

    def reset(self):
        self.board.fill(0)
        self.current_player = 1
        return self.board.flatten()

    def available_actions(self):
        return list(zip(*np.where(self.board == 0)))

    def make_move(self, action):
        self.board[action] = self.current_player
        self.current_player = 3 - self.current_player  # Switch player

    def check_winner(self):
        for player in [1, 2]:
            if any(np.all(self.board[i, :] == player) for i in range(3)) or \
               any(np.all(self.board[:, i] == player) for i in range(3)) or \
               np.all(np.diag(self.board) == player) or \
               np.all(np.diag(np.fliplr(self.board)) == player):
                return player
        if not self.available_actions():
            return 0  # Draw
        return None  # Game continues

    def render(self):
        print(self.board)
class QLearningAgent:
    def __init__(self, learning_rate=0.1, discount_factor=0.9, exploration_rate=1.0, exploration_decay=0.99):
        self.q_table = {}  # State-action values
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.exploration_rate = exploration_rate
        self.exploration_decay = exploration_decay

    def get_state_key(self, state):
        return str(state)

    def get_action(self, state):
        if random.random() < self.exploration_rate:
            return random.choice(self.available_actions(state))
        state_key = self.get_state_key(state)
        return max(self.q_table.get(state_key, {}), key=self.q_table.get(state_key, {}).get, default=None)

    def update(self, state, action, reward, next_state):
        state_key = self.get_state_key(state)
        next_state_key = self.get_state_key(next_state)

        if state_key not in self.q_table:
            self.q_table[state_key] = {a: 0 for a in self.available_actions(state)}

        old_value = self.q_table[state_key].get(action, 0)
        future_rewards = max(self.q_table.get(next_state_key, {}).values(), default=0)

        # Update Q-value
        new_value = (1 - self.learning_rate) * old_value + self.learning_rate * (reward + self.discount_factor * future_rewards)
        self.q_table[state_key][action] = new_value

    def decay_exploration(self):
        self.exploration_rate *= self.exploration_decay

    def available_actions(self, state):
        return list(zip(*np.where(state.reshape(3, 3) == 0)))
def train_agent(episodes):
    agent = QLearningAgent()
    game = TicTacToe()

    for episode in range(episodes):
        state = game.reset()
        done = False
        while not done:
            action = agent.get_action(state)
            game.make_move(action)
            winner = game.check_winner()
            next_state = game.board.flatten()

            if winner == 1:
                reward = 1
                done = True
            elif winner == 2:
                reward = -1
                done = True
            elif winner == 0:
                reward = 0.5  # Draw
                done = True
            else:
                reward = 0

            agent.update(state, action, reward, next_state)
            state = next_state

        agent.decay_exploration()

    return agent

# Train the agent
trained_agent = train_agent(10000)
def play_game(agent):
    game = TicTacToe()
    game.render()

    while True:
        # Human player
        action = tuple(map(int, input("Enter your move (row col): ").split()))
        game.make_move(action)
        game.render()
        if game.check_winner() is not None:
            break

        # Agent's turn
        state = game.board.flatten()
        action = agent.get_action(state)
        game.make_move(action)
        game.render()
        if game.check_winner() is not None:
            break

# Play a game against the trained agent
play_game(trained_agent)
